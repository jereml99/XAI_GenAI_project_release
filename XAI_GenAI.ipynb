{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Responsible AI: XAI GenAI project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Background\n",
    "\n",
    "\n",
    "\n",
    "Based on the previous lessons on explainability, post-hoc methods are used to explain the model, such as saliency map, SmoothGrad, LRP, LIME, and SHAP. Take LRP (Layer Wise Relevance Propagation) as an example; it highlights the most relevant pixels to obtain a prediction of the class \"cat\" by backpropagating the relevance. (image source: [Montavon et. al (2016)](https://giorgiomorales.github.io/Layer-wise-Relevance-Propagation-in-Pytorch/))\n",
    "\n",
    "<!-- %%[markdown] -->\n",
    "![LRP example](images/catLRP.jpg)\n",
    "\n",
    "Another example is about text sentiment classification, here we show a case of visualizing the importance of words given the prediction of 'positive':\n",
    "\n",
    "![text example](images/textGradL2.png)\n",
    "\n",
    "where the words highlight with darker colours indicate to be more critical in predicting the sentence to be 'positive' in sentiment.\n",
    "More examples could be found [here](http://34.160.227.66/?models=sst2-tiny&dataset=sst_dev&hidden_modules=Explanations_Attention&layout=default).\n",
    "\n",
    "Both cases above require the class or the prediction of the model. But:\n",
    "\n",
    "***How do you explain a model that does not predict but generates?***\n",
    "\n",
    "In this project, we will work on explaining the generative model based on the dependency between words. We will first look at a simple example, and using Point-wise Mutual Information (PMI) to compute the saliency map of the sentence. After that we will contruct the expereiment step by step, followed by exercises and questions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. A simple example to start with\n",
    "Given a sample sentence: \n",
    "> *Tokyo is the capital city of Japan.* \n",
    "\n",
    "We are going to explain this sentence by finding the dependency using a saliency map between words.\n",
    "The dependency of two words in the sentence could be measured by [Point-wise mutual information (PMI)](https://en.wikipedia.org/wiki/Pointwise_mutual_information): \n",
    "\n",
    "\n",
    "Mask two words out, e.g. \n",
    "> \\[MASK-1\\] is the captial city of \\[MASK-2\\].\n",
    "\n",
    "\n",
    "Ask the generative model to fill in the sentence 10 times, and we have:\n",
    "\n",
    "| MASK-1      | MASK-2 |\n",
    "| ----------- | ----------- |\n",
    "|    tokyo   |     japan   |\n",
    "|  paris  |     france    |\n",
    "|  london  |     england    |\n",
    "|  paris  |     france    |\n",
    "|  beijing |  china |\n",
    "|    tokyo   |     japan   |\n",
    "|  paris  |     france    |\n",
    "|  paris  |     france    |\n",
    "|  london  |     england    |\n",
    "|  beijing |  china |\n",
    "\n",
    "PMI is calculated by: \n",
    "\n",
    "$PMI(x,y)=log_2⁡ \\frac{p(\\{x,y\\}| s-\\{x,y\\})}{P(\\{x\\}|s-\\{x,y\\})P(\\{y\\}|s-\\{x,y\\})}$\n",
    "\n",
    "where $x$, $y$ represents the words that we masked out, $s$ represents the setence, and $s-\\{x,y\\}$ represents the sentences tokens after removing the words $x$ and $y$.\n",
    "\n",
    "In this example we have $PMI(Tokyo, capital) = log_2 \\frac{0.2}{0.2 * 0.2} = 2.32$\n",
    "\n",
    "Select an interesting word in the sentences; we can now compute the PMI between all other words and the chosen word using the generative model:\n",
    "(Here, we use a longer sentence and run 20 responses per word.)\n",
    "![](images/resPMI.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Preparation\n",
    "### 2.1 Conda enviroment\n",
    "\n",
    "```\n",
    "conda env create -f environment.yml\n",
    "conda activate xai_llm\n",
    "```\n",
    "\n",
    "\n",
    "### 2.2 Download the offline LLM\n",
    "\n",
    "We use the offline LLM model from hugging face. It's approximately 5 GB.\n",
    "Download it using the comman below, and save it under `./models/`.\n",
    "```\n",
    "huggingface-cli download TheBloke/openchat-3.5-0106-GGUF openchat-3.5-0106.Q4_K_M.gguf --local-dir . --local-dir-use-symlinks False\n",
    "# credit to https://huggingface.co/TheBloke/openchat-3.5-0106-GGUF\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Mask the sentence and get the responses from LLM\n",
    "### 3.1 Get the input sentence\n",
    "\n",
    "**Remember to change the anchor word index when changing the input sentence.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_input():\n",
    "    # ideally this reads inputs from a file, now it just takes an input\n",
    "    return input(\"Enter a sentence: \")\n",
    "    \n",
    "anchor_word_idx = 0 # the index of the interested word\n",
    "prompts_per_word = 20 # number of generated responses  \n",
    "\n",
    "sentence =\"Tokyo is the capital of Japan\"\n",
    "sentence = sentence.lower()\n",
    "print(\"Sentence: \", sentence)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.ChatModel import ChatModel\n",
    "model_name = \"openchat\"\n",
    "model = ChatModel(model_name)\n",
    "print(f\"Model: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Run the prompts and get all the responses\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.command_generator import generate_prompts, prefix_prompt\n",
    "from tools.evaluate_response import get_replacements\n",
    "from tqdm import tqdm\n",
    "\n",
    "def run_prompts(model, sentence, anchor_idx, prompts_per_word=20):\n",
    "    prompts = generate_prompts(sentence, anchor_idx)\n",
    "    all_replacements = []\n",
    "    for prompt in prompts:\n",
    "        replacements = []\n",
    "        for _ in tqdm(\n",
    "            range(prompts_per_word),\n",
    "            desc=f\"Input: {prompt}\",\n",
    "        ):\n",
    "            response = model.get_response(\n",
    "                prefix_prompt(prompt),\n",
    "            ).strip()\n",
    "            if response:\n",
    "                replacement = get_replacements(prompt, response)\n",
    "                if replacement:\n",
    "                    replacements.append(tuple(replacement))\n",
    "        if len(replacements) > 0:\n",
    "            all_replacements.append(replacements)\n",
    "    return all_replacements\n",
    "\n",
    "all_responses = run_prompts(model, sentence, anchor_word_idx, prompts_per_word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 EXERCISE: compute the PMI for each word\n",
    "\n",
    "$PMI(x,y)=log_2⁡ \\frac{p(\\{x,y\\}| s-\\{x,y\\})}{P(\\{x\\}|s-\\{x,y\\})P(\\{y\\}|s-\\{x,y\\})}$\n",
    "\n",
    "* Compute the $P(x)$, $P(y)$ and $P(x,y)$ first and print it out.\n",
    "* Compute the PMI for each word.\n",
    "* Visualize the result by coloring. Tips: you might need to normalize the result first. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "def visualize_replacements(all_responses, sentence, anchor_word_idx):\n",
    "    prompts = generate_prompts(sentence, anchor_word_idx)\n",
    "    for i, replacements in enumerate(all_responses):\n",
    "        prompt = prompts[i]\n",
    "        data = []\n",
    "        \n",
    "        for j, replacement in enumerate(replacements):\n",
    "            filled_prompt = prompt.replace(\"[MASK]\", replacement[0], 1).replace(\"[MASK]\", replacement[1], 1)\n",
    "            data.append({\n",
    "                \"No.\": j + 1,  # Add numbering for replacements\n",
    "                \"Filled Prompt\": filled_prompt,\n",
    "                \"Replacements\": f\"({replacement[0]}, {replacement[1]})\"\n",
    "            })\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        # Display prompt with Markdown\n",
    "        display(Markdown(f\"### Prompt: `{prompt}`\"))\n",
    "        \n",
    "        styled_df = df.style.hide(axis=\"index\")\n",
    "        display(styled_df)\n",
    "        print(\"\\n\")  # Add spacing between prompts for better separation\n",
    "\n",
    "\n",
    "\n",
    "visualize_replacements(all_responses, sentence, anchor_word_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strict_similarity(word1, word2, model = None):\n",
    "    return int(word1 == word2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Debug Information for Sentence: `tokyo is the capital of japan`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Word</th>\n",
       "      <th>P({x}|s - {x, y})</th>\n",
       "      <th>P({y}|s - {x, y})</th>\n",
       "      <th>P({x, y}|s - {x, y})</th>\n",
       "      <th>PMI</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tokyo</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>19/20</td>\n",
       "      <td>19/20</td>\n",
       "      <td>19/20</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>13/20</td>\n",
       "      <td>11/20</td>\n",
       "      <td>11/20</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>capital</td>\n",
       "      <td>17/20</td>\n",
       "      <td>17/20</td>\n",
       "      <td>17/20</td>\n",
       "      <td>0.23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>18/20</td>\n",
       "      <td>16/20</td>\n",
       "      <td>16/20</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>japan</td>\n",
       "      <td>5/20</td>\n",
       "      <td>5/20</td>\n",
       "      <td>5/20</td>\n",
       "      <td>2.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Word P({x}|s - {x, y}) P({y}|s - {x, y}) P({x, y}|s - {x, y})   PMI\n",
       "0    tokyo               N/A               N/A                  N/A  0.00\n",
       "1       is             19/20             19/20                19/20  0.07\n",
       "2      the             13/20             11/20                11/20  0.62\n",
       "3  capital             17/20             17/20                17/20  0.23\n",
       "4       of             18/20             16/20                16/20  0.15\n",
       "5    japan              5/20              5/20                 5/20  2.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x200 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "\n",
    "from typing import Callable\n",
    "\n",
    "def calculate_pmi(sentence, anchor_word_idx, all_responses, similarity_function: Callable[[str, str, object], int] = None, debug=False):\n",
    "    words = sentence.split()\n",
    "    anchor_word = words[anchor_word_idx]\n",
    "    pmi_list = []\n",
    "    if similarity_function is None:\n",
    "        similarity_function = strict_similarity\n",
    "    if debug:\n",
    "        debug_data = [] \n",
    "    response_index = 0\n",
    "    for word_index, word in enumerate(words):\n",
    "        if word_index != anchor_word_idx:\n",
    "            if anchor_word_idx < word_index:\n",
    "                x_word, y_word = anchor_word, word\n",
    "            else:\n",
    "                x_word, y_word = word, anchor_word\n",
    "            \n",
    "            sum_of_X_similaritties = np.sum([similarity_function(x_word, response[0]) for response in all_responses[response_index]])\n",
    "            sum_of_Y_similaritties = np.sum([similarity_function(y_word, response[1]) for response in all_responses[response_index]])\n",
    "            sum_of_XY_similaritties = np.sum([similarity_function(x_word, response[0]) * similarity_function(y_word, response[1]) for response in all_responses[response_index]])\n",
    "                \n",
    "            \n",
    "            total = len(all_responses[response_index])\n",
    "            p_x = sum_of_X_similaritties / total\n",
    "            p_y = sum_of_Y_similaritties / total\n",
    "            p_xy = sum_of_XY_similaritties / total\n",
    "            epsilon = 1e-10\n",
    "            pmi = np.log2((p_xy+epsilon) / (p_x * p_y + epsilon))\n",
    "            pmi_list.append(pmi)\n",
    "            response_index += 1\n",
    "            if debug:\n",
    "                debug_data.append({\n",
    "                    \"Word\": word,\n",
    "                    f\"P({{x}}|s - {{x, y}})\": f\"{sum_of_X_similaritties}/{total}\",\n",
    "                    f\"P({{y}}|s - {{x, y}})\": f\"{sum_of_Y_similaritties}/{total}\",\n",
    "                    f\"P({{x, y}}|s - {{x, y}})\": f\"{sum_of_XY_similaritties}/{total}\",\n",
    "                    \"PMI\": round(pmi, 2)\n",
    "                })\n",
    "        else:\n",
    "            pmi_list.append(0)\n",
    "            if debug:\n",
    "                debug_data.append({\n",
    "                    \"Word\": word,\n",
    "                    f\"P({{x}}|s - {{x, y}})\": \"N/A\",\n",
    "                    f\"P({{y}}|s - {{x, y}})\": \"N/A\",\n",
    "                    f\"P({{x, y}}|s - {{x, y}})\": \"N/A\",\n",
    "                    \"PMI\": 0\n",
    "                })\n",
    "    \n",
    "    if debug:\n",
    "        debug_df = pd.DataFrame(debug_data)\n",
    "        display(Markdown(f\"### Debug Information for Sentence: `{sentence}`\"))\n",
    "        display(debug_df)\n",
    "    \n",
    "    return pmi_list\n",
    "\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "def visualize_pmi(pmi_list, sentence, anchor_word_idx):\n",
    "    words = sentence.split()\n",
    "    pmi_values = np.array(pmi_list)\n",
    "    \n",
    "    # Normalize the PMI values\n",
    "    norm = plt.Normalize(pmi_values[np.arange(len(pmi_values)) != anchor_word_idx].min(), \n",
    "                         pmi_values[np.arange(len(pmi_values)) != anchor_word_idx].max())\n",
    "    norm_pmi_values = norm(pmi_values)\n",
    "    \n",
    "    # Create a color map\n",
    "    cmap = plt.get_cmap('coolwarm')\n",
    "    colors = cmap(norm_pmi_values)\n",
    "    \n",
    "    # Plot the words with colors based on PMI values\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    for i, word in enumerate(words):\n",
    "        color = 'green' if i == anchor_word_idx else colors[i]\n",
    "        plt.text(i, 1, word, fontsize=12, ha='center', va='center', color=color)\n",
    "        if i != anchor_word_idx:\n",
    "            plt.text(i, 0.5, f\"{pmi_values[i]:.2f}\", fontsize=10, ha='center', va='center', color='black')\n",
    "            plt.text(i, 0, f\"{norm_pmi_values[i]:.2f}\", fontsize=10, ha='center', va='center', color='black')\n",
    "    \n",
    "    # Add a quick legend\n",
    "    plt.text(-1, 1, \"Words\", fontsize=12, ha='center', va='center', color='black')\n",
    "    plt.text(-1, 0.5, \"PMI\", fontsize=10, ha='center', va='center', color='black')\n",
    "    plt.text(-1, 0, \"Norm PMI\", fontsize=10, ha='center', va='center', color='black')\n",
    "    \n",
    "    plt.xlim(-2, len(words))\n",
    "    plt.ylim(-0.5, 1.5)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "pmi_list = calculate_pmi(sentence, anchor_word_idx, all_responses, debug=True)\n",
    "visualize_pmi(pmi_list, sentence, anchor_word_idx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## 4. EXERCISE: Try more examples; maybe come up with your own. Report the results.\n",
    "\n",
    "* Try to come up with more examples and, change the anchor word/number of responses, and observe the results. What does the explanation mean? Do you think it's a nice explanation? Why and why not? \n",
    "* What's the limitation of the current method? When does the method fail to explain? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_expermient(sentence, anchor_word_idx, prompts_per_word, model: ChatModel, similarity_function= None, debug=False):\n",
    "    sentence = sentence.lower()\n",
    "    all_responses = run_prompts(model, sentence, anchor_word_idx, prompts_per_word)\n",
    "    if debug:\n",
    "        # clean jupyter notebook output\n",
    "        from IPython.display import clear_output\n",
    "        clear_output()\n",
    "        visualize_replacements(all_responses, sentence, anchor_word_idx)\n",
    "    pmi_list = calculate_pmi(sentence, anchor_word_idx, all_responses, similarity_function, debug=debug)\n",
    "    visualize_pmi(pmi_list, sentence, anchor_word_idx)\n",
    "\n",
    "# make_expermient(sentence, anchor_word_idx, prompts_per_word, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_expermient(\"The capital of Japan is Tokyo\", 5, 20, model, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_expermient(\"The bank by the river is closed\", 1, 20, model, debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_expermient(\"Despite the storm the ship sailed toward its goal\", 4, 20, model, debug=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Bonus Exercises\n",
    "### 5.1 Language pre-processing. \n",
    "In this exercise, we only lower the letters and split sentences into words; there's much more to do to pre-process the language. For example, contractions (*I'll*, *She's*, *world's*), suffix and prefix, compound words (*hard-working*). It's called word tokenization in NLP, and there are some Python packages that can do such work for us, e.g. [*TextBlob*](https://textblob.readthedocs.io/en/dev/). \n",
    "\n",
    "\n",
    "### 5.2 Better word matching\n",
    "In the above example of\n",
    "> Tokyo is the capital of Japan and a popular metropolis in the world.\n",
    "\n",
    ", GenAI never gives the specific word 'metropolis' when masking it out; instead, sometimes it provides words like 'city', which is not the same word but has a similar meaning. Instead of measuring the exact matching of certain words (i.e. 0 or 1), we can also measure the similarity of two words, e.g. the cosine similarity in word embedding, which ranges from 0 to 1. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity: 0.9999998807907104\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "def compute_similarity(word1, word2, model):\n",
    "    # Encode words into embeddings\n",
    "    vec1 = model.encode([word1])\n",
    "    vec2 = model.encode([word2])\n",
    "    \n",
    "    # Compute cosine similarity\n",
    "    similarity = cosine_similarity(vec1, vec2)[0][0]\n",
    "    return similarity\n",
    "\n",
    "embedding_model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "similarity = compute_similarity(\"Elo\", \"Elo\", embedding_model)\n",
    "print(f\"Cosine Similarity: {similarity}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xai_llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
